{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1)\n",
    "import sys\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from anchor import utils\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from int_met import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'Datasets/drugscom/'\n",
    "train_raw = pd.read_csv(str(dataset_folder+'drugsComTrain_raw.csv'))\n",
    "test_raw = pd.read_csv(str(dataset_folder+'drugsComTest_raw.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_raw[['review','rating']]\n",
    "test = train_raw[['review','rating']]\n",
    "df_all = pd.concat([train,test]).reset_index()\n",
    "del df_all['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "not_stop = [\"aren't\",\"couldn't\",\"didn't\",\"doesn't\",\"don't\",\"hadn't\",\"hasn't\",\"haven't\",\"isn't\",\"mightn't\",\"mustn't\",\"needn't\",\"no\",\"nor\",\"not\",\"shan't\",\"shouldn't\",\"wasn't\",\"weren't\",\"wouldn't\"]\n",
    "for i in not_stop:\n",
    "    if i in stops:\n",
    "        stops.remove(i)\n",
    "    \n",
    "stemmer = SnowballStemmer('english')\n",
    "def review_to_words(raw_review):\n",
    "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
    "    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)\n",
    "    words = letters_only.lower().split()\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    stemming_words = [stemmer.stem(w) for w in meaningful_words]\n",
    "    return( ' '.join(stemming_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 49s\n"
     ]
    }
   ],
   "source": [
    "%time df_all['review_clean'] = df_all['review'].apply(review_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['sentiment'] = df_all[\"rating\"].apply(lambda x: 1 if x > 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_all, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = 'word', \n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None, \n",
    "                             stop_words = None, \n",
    "                             min_df = 2,\n",
    "                             max_features = 5000\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.2 s\n",
      "Wall time: 5.01 s\n"
     ]
    }
   ],
   "source": [
    "%time X_train = vectorizer.fit_transform(df_train['review_clean'])\n",
    "%time X_test = vectorizer.transform(df_test['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['sentiment']\n",
    "y_test = df_test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickling_on = open(\"textrf.pickle\",\"rb\")\n",
    "c = pickle.load(pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.9998704525370483\n",
      "Test 0.968156156945997\n"
     ]
    }
   ],
   "source": [
    "c = sklearn.ensemble.RandomForestClassifier(n_estimators=100, n_jobs=3, random_state=1)\n",
    "c.fit(X_train, y_train)\n",
    "predict_fn = lambda x: c.predict(x)\n",
    "print('Train', sklearn.metrics.accuracy_score(y_train, predict_fn(X_train)))\n",
    "print('Test', sklearn.metrics.accuracy_score(y_test, predict_fn(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['negative','positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pip_line = make_pipeline(vectorizer, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lyrica almost year first start realli skinni so weight gain didn bother but gain lbs not good go go back gabapentin help get morphin eye dri blurri fart time fat begin year hurt but side affect too much'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.review_clean.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "%time exp = explainer.explain_instance(df_test.review_clean.iloc[idx], pip_line.predict_proba, num_features=6, top_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('didn', 0.13273120519723347),\n",
       " ('not', 0.11264088701252714),\n",
       " ('gain', 0.10231757664617594),\n",
       " ('eye', 0.09774650554997463),\n",
       " ('blurri', 0.07033445785436285),\n",
       " ('fart', 0.05998285716333729)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.as_list(label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fn = lambda i: explainer.explain_instance(df_test.review_clean.iloc[i], pip_line.predict_proba, num_features=5, top_labels=1)\n",
    "def exp_fn_blk(xtest, exp_fn):\n",
    "    exp1 = []\n",
    "    for i in range(len(xtest)):\n",
    "        exp = exp_fn(i)\n",
    "        exp1.append(np.array(exp.as_map()[exp.available_labels()[0]]))\n",
    "    return np.array(exp1)\n",
    "exp_fn_wrap = lambda x: exp_fn_blk(x, exp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%time exp1 = exp_fn_blk(df_test.review_clean.iloc[0:10], exp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done exp1\n"
     ]
    }
   ],
   "source": [
    "exp1 = exp_fn_blk(df_test.review_clean.iloc[0:400], exp_fn)\n",
    "print('done exp1')\n",
    "exp2 = exp_fn_blk(df_test.review_clean.iloc[:400], exp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100.0, 0, 400)\n"
     ]
    }
   ],
   "source": [
    "i = calc_identity(exp1,exp2)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 399, 159201, 0.0)\n"
     ]
    }
   ],
   "source": [
    "s = calc_separability(df_test.review_clean.iloc[:400].values, exp_fn_wrap)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_exp(exp, feature_num):\n",
    "    enc_exp = np.zeros((len(exp),feature_num))\n",
    "    for i in range(len(exp)):\n",
    "        for j in range(len(exp[i])):\n",
    "            enc_exp[i][int(exp[i][j,0])] = exp[i][j,1]\n",
    "    return enc_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc1 = enc_exp(exp1, 5000)\n",
    "enc2 = enc_exp(exp2, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\cluster\\k_means_.py:896: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  return_n_iter=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106, 400)\n"
     ]
    }
   ],
   "source": [
    "sb = calc_stability(enc1, df_test.sentiment.iloc[:400].values)\n",
    "print(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickling_on = open(\"textrf.pickle\",\"wb\")\n",
    "pickle.dump(c, pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
