{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import sys\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "from int_met import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'Datasets/'\n",
    "dataset = utils.load_dataset('mortality', balance=True, dataset_folder=dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(dataset.class_names, dataset.feature_names, dataset.data, dataset.categorical_names)\n",
    "explainer.fit(dataset.train, dataset.labels_train, dataset.validation, dataset.labels_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.9754784688995215\n",
      "Test 0.8169856459330144\n",
      "Train 0.9755413550207725\n",
      "Test 0.8165940366972477\n"
     ]
    }
   ],
   "source": [
    "c = sklearn.ensemble.RandomForestClassifier(n_estimators=100, n_jobs=5, random_state= 46)\n",
    "c.fit(explainer.encoder.transform(dataset.train), dataset.labels_train)\n",
    "predict_fn = lambda x: c.predict(explainer.encoder.transform(x))\n",
    "print('Train', sklearn.metrics.accuracy_score(dataset.labels_train, predict_fn(dataset.train)))\n",
    "print('Test', sklearn.metrics.accuracy_score(dataset.labels_test, predict_fn(dataset.test)))\n",
    "print('Train', sklearn.metrics.roc_auc_score(dataset.labels_train, predict_fn(dataset.train)))\n",
    "print('Test', sklearn.metrics.roc_auc_score(dataset.labels_test, predict_fn(dataset.test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fn_bulk = lambda x: np.array([np.array(explainer.explain_instance(x[idx], c.predict, threshold=0.95).names()) for idx in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = dataset.test[:412]\n",
    "unique_data, unique_idx = np.unique(temp,axis=0,return_index=True)\n",
    "unique_label = dataset.labels_test[unique_idx]\n",
    "unique_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%time exp2 = exp_fn_bulk(unique_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%time exp2 = exp_fn_bulk(unique_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%time exp2 = exp_fn_bulk(unique_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time exp1 = exp_fn_bulk(unique_data)\n",
    "%time exp2 = exp_fn_bulk(unique_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89.25, 43, 400)\n"
     ]
    }
   ],
   "source": [
    "i = calc_identity(exp1,exp2)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 400, 160000, 0.06375)\n"
     ]
    }
   ],
   "source": [
    "s = calc_separability(exp1)\n",
    "print (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy, copy\n",
    "def get_cat_names(cat_feats, cate_names, feat_names):\n",
    "    cat_names = deepcopy(cate_names)\n",
    "    for i in cat_feats:\n",
    "        for j in range(len(cat_names[i])):\n",
    "            cat_names[i][j] = feat_names[i] + ' = ' + cat_names[i][j]\n",
    "    return cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = get_cat_names(list(set(dataset.categorical_features) - set(dataset.ordinal_features)), dataset.categorical_names, dataset.feature_names)\n",
    "flat_cat_names = [item for sublist in cat_names.values() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_exp(exp, flat_cat_names):\n",
    "    enc_exp = np.zeros((1,len(flat_cat_names)))\n",
    "    for i in range(len(flat_cat_names)):\n",
    "        if flat_cat_names[i] in exp:\n",
    "            enc_exp[0,i] = 1\n",
    "    return enc_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_exps = np.array([encode_exp(exp1[i], flat_cat_names) for i in range(len(exp1))]).squeeze()\n",
    "enc_exps2 = np.array([encode_exp(exp2[i], flat_cat_names) for i in range(len(exp2))]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\cluster\\k_means_.py:896: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  return_n_iter=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 400)\n"
     ]
    }
   ],
   "source": [
    "sb = calc_stability(enc_exps, unique_label)\n",
    "print(sb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
